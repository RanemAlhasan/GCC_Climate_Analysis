{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1aab0802-7c85-41aa-acf0-9e2aea3f72a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Bronze_to_Silver (Cleaning)\n",
    "This notebook cleans and organizes raw Bronze climate data into a usable dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d73ca232-18ad-47c3-b5b3-7e19c691a704",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\n",
    "    \"fs.azure.account.key.qatarclimateanalysis.dfs.core.windows.net\",\n",
    "    \"<account key>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fc59004-dfd6-4ca9-b3b7-6d88f39c14cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>DATA_VALUE</th><th>DATE</th><th>ELEMENT</th><th>ID</th><th>MFLAG</th><th>OBS_TIME</th><th>QFLAG</th><th>SFLAG</th></tr></thead><tbody><tr><td>125</td><td>20150101</td><td>TMIN</td><td>AE000041196</td><td>null</td><td>null</td><td>null</td><td>S</td></tr><tr><td>0</td><td>20150101</td><td>PRCP</td><td>AE000041196</td><td>null</td><td>null</td><td>null</td><td>S</td></tr><tr><td>206</td><td>20150101</td><td>TAVG</td><td>AE000041196</td><td>H</td><td>null</td><td>null</td><td>S</td></tr><tr><td>286</td><td>20150101</td><td>TMAX</td><td>AEM00041194</td><td>null</td><td>null</td><td>null</td><td>S</td></tr><tr><td>180</td><td>20150101</td><td>TMIN</td><td>AEM00041194</td><td>null</td><td>null</td><td>null</td><td>S</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         125,
         20150101,
         "TMIN",
         "AE000041196",
         null,
         null,
         null,
         "S"
        ],
        [
         0,
         20150101,
         "PRCP",
         "AE000041196",
         null,
         null,
         null,
         "S"
        ],
        [
         206,
         20150101,
         "TAVG",
         "AE000041196",
         "H",
         null,
         null,
         "S"
        ],
        [
         286,
         20150101,
         "TMAX",
         "AEM00041194",
         null,
         null,
         null,
         "S"
        ],
        [
         180,
         20150101,
         "TMIN",
         "AEM00041194",
         null,
         null,
         null,
         "S"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "DATA_VALUE",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "DATE",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ELEMENT",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "MFLAG",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "OBS_TIME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "QFLAG",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "SFLAG",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bronze_path = \"abfss://lakehouse@qatarclimateanalysis.dfs.core.windows.net/bronze/gcc_bronze.parquet\"\n",
    "\n",
    "# Read bronze data\n",
    "df_bronze = spark.read.parquet(bronze_path)\n",
    "display(df_bronze.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e6cd60c-7a61-4fb8-86fb-5bfcb26c0682",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Data Scaling and Columns Pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6600cd7-55bc-4d78-95ff-1a538fa71581",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>date</th><th>PRCP</th><th>SNWD</th><th>TAVG</th><th>TMAX</th><th>TMIN</th></tr></thead><tbody><tr><td>SAM00041084</td><td>2015-05-09</td><td>null</td><td>null</td><td>26.8</td><td>null</td><td>20.4</td></tr><tr><td>SAM00041114</td><td>2019-01-02</td><td>null</td><td>null</td><td>16.8</td><td>24.0</td><td>10.0</td></tr><tr><td>SAM00040405</td><td>2019-08-05</td><td>null</td><td>null</td><td>34.9</td><td>42.0</td><td>25.2</td></tr><tr><td>AEM00041218</td><td>2022-06-13</td><td>null</td><td>null</td><td>37.1</td><td>null</td><td>null</td></tr><tr><td>SAM00041136</td><td>2023-02-10</td><td>null</td><td>null</td><td>19.4</td><td>null</td><td>11.5</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "SAM00041084",
         "2015-05-09",
         null,
         null,
         26.8,
         null,
         20.4
        ],
        [
         "SAM00041114",
         "2019-01-02",
         null,
         null,
         16.8,
         24,
         10
        ],
        [
         "SAM00040405",
         "2019-08-05",
         null,
         null,
         34.9,
         42,
         25.2
        ],
        [
         "AEM00041218",
         "2022-06-13",
         null,
         null,
         37.1,
         null,
         null
        ],
        [
         "SAM00041136",
         "2023-02-10",
         null,
         null,
         19.4,
         null,
         11.5
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "PRCP",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "SNWD",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "TAVG",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "TMAX",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "TMIN",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import col, to_date, first\n",
    "\n",
    "# 1. Convert DATE from YYYYMMDD to a real date\n",
    "df = df_bronze.withColumn(\"date\", to_date(col(\"DATE\").cast(\"string\"), \"yyyyMMdd\"))\n",
    "\n",
    "# 2. Fix scaling by dividing DATA_VALUE by 10\n",
    "df = df.withColumn(\"value\", col(\"DATA_VALUE\") / 10)\n",
    "\n",
    "# 3. Remove rows where date is missing\n",
    "df = df.dropna(subset=[\"date\"])\n",
    "\n",
    "# 4. Pivot ELEMENT values into columns (TMAX, TMIN, TAVG, PRCP…)\n",
    "df_pivot = (\n",
    "    df.groupBy(\"ID\", \"date\")\n",
    "      .pivot(\"ELEMENT\")\n",
    "      .agg(first(\"value\"))\n",
    ")\n",
    "\n",
    "# 5. show the cleaned daily dataset\n",
    "display(df_pivot.limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f527c961-7401-42f5-8afa-8ee21d5b4691",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Removing Irrelevant Columns and Fixing Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c71a4446-c41a-42fb-be2a-4ebdbba30081",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>date</th><th>PRCP</th><th>TAVG</th><th>TMAX</th><th>TMIN</th></tr></thead><tbody><tr><td>SAM00040435</td><td>2015-03-25</td><td>0.0</td><td>26.7</td><td>31.0</td><td>15.0</td></tr><tr><td>SAM00040357</td><td>2018-09-13</td><td>0.0</td><td>34.6</td><td>43.0</td><td>26.9</td></tr><tr><td>SAM00040405</td><td>2019-11-15</td><td>0.0</td><td>19.5</td><td>25.0</td><td>15.0</td></tr><tr><td>SAM00040373</td><td>2020-07-27</td><td>0.0</td><td>41.2</td><td>48.0</td><td>34.0</td></tr><tr><td>SAW00032502</td><td>2022-12-13</td><td>0.0</td><td>18.9</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "SAM00040435",
         "2015-03-25",
         0,
         26.7,
         31,
         15
        ],
        [
         "SAM00040357",
         "2018-09-13",
         0,
         34.6,
         43,
         26.9
        ],
        [
         "SAM00040405",
         "2019-11-15",
         0,
         19.5,
         25,
         15
        ],
        [
         "SAM00040373",
         "2020-07-27",
         0,
         41.2,
         48,
         34
        ],
        [
         "SAW00032502",
         "2022-12-13",
         0,
         18.9,
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "PRCP",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "TAVG",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "TMAX",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "TMIN",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# 1. Replace PRCP nulls with 0 (no rain reported)\n",
    "df_silver_clean = df_pivot.withColumn(\n",
    "    \"PRCP\", coalesce(col(\"PRCP\"), lit(0.0))\n",
    ")\n",
    "\n",
    "# 2. Drop snow depth (SNWD) — irrelevant in GCC region\n",
    "df_silver_clean = df_silver_clean.drop(\"SNWD\")\n",
    "\n",
    "# 3. Drop all flag columns (not useful for ML)\n",
    "df_silver_clean = df_silver_clean.drop(\"MFLAG\", \"QFLAG\", \"SFLAG\", \"OBS_TIME\")\n",
    "\n",
    "# 4. Display the final SILVER table\n",
    "display(df_silver_clean.limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5116a2b-6af0-438b-a925-b8ea803dd652",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Filling Missing Temprature Values (Forward/Backward Fill in Silver Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "656ba619-7273-48bd-8a92-916c7865f365",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>date</th><th>PRCP</th><th>TAVG</th><th>TMAX</th><th>TMIN</th></tr></thead><tbody><tr><td>AE000041196</td><td>2015-01-01</td><td>0.0</td><td>20.6</td><td>27.4</td><td>12.5</td></tr><tr><td>AE000041196</td><td>2015-01-02</td><td>0.0</td><td>19.9</td><td>27.4</td><td>12.7</td></tr><tr><td>AE000041196</td><td>2015-01-03</td><td>0.0</td><td>20.6</td><td>27.4</td><td>14.0</td></tr><tr><td>AE000041196</td><td>2015-01-04</td><td>0.0</td><td>19.7</td><td>27.4</td><td>14.0</td></tr><tr><td>AE000041196</td><td>2015-01-05</td><td>0.0</td><td>19.6</td><td>27.0</td><td>14.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "AE000041196",
         "2015-01-01",
         0,
         20.6,
         27.4,
         12.5
        ],
        [
         "AE000041196",
         "2015-01-02",
         0,
         19.9,
         27.4,
         12.7
        ],
        [
         "AE000041196",
         "2015-01-03",
         0,
         20.6,
         27.4,
         14
        ],
        [
         "AE000041196",
         "2015-01-04",
         0,
         19.7,
         27.4,
         14
        ],
        [
         "AE000041196",
         "2015-01-05",
         0,
         19.6,
         27,
         14
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "PRCP",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "TAVG",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "TMAX",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "TMIN",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# window per station, ordered by date (forward direction)\n",
    "# Move through each station’s data، looks forward in time\n",
    "w_ffill = Window.partitionBy(\"ID\").orderBy(\"date\") \\\n",
    "    .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "# window per station, ordered by date in reverse (backward direction)\n",
    "# Move through each station’s data، looks backward in time\n",
    "w_bfill = Window.partitionBy(\"ID\").orderBy(col(\"date\").desc()) \\\n",
    "    .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "\n",
    "# Note\n",
    "# first time = forward fill\n",
    "# second time = backward fill\n",
    "# third time = choose the best value (original → ffill → bfill)\n",
    "# Original values preserved\n",
    "\n",
    "# 1. Fill TMAX using forward fill (previous valid day)\n",
    "df_silver_filled = df_silver_clean.withColumn(\n",
    "    \"TMAX_ffill\",\n",
    "    last(\"TMAX\", ignorenulls=True).over(w_ffill)\n",
    ")\n",
    "\n",
    "# 2. Fill TMAX using backward fill (next valid day)\n",
    "df_silver_filled = df_silver_filled.withColumn(\n",
    "    \"TMAX_bfill\",\n",
    "    last(\"TMAX\", ignorenulls=True).over(w_bfill)\n",
    ")\n",
    "\n",
    "# 3. Combine original TMAX → forward fill → backward fill\n",
    "df_silver_filled = df_silver_filled.withColumn(\n",
    "    \"TMAX\",\n",
    "    coalesce(col(\"TMAX\"), col(\"TMAX_ffill\"), col(\"TMAX_bfill\"))\n",
    ")\n",
    "\n",
    "\n",
    "# 4. Fill TMIN using forward fill (previous day)\n",
    "df_silver_filled = df_silver_filled.withColumn(\n",
    "    \"TMIN_ffill\",\n",
    "    last(\"TMIN\", ignorenulls=True).over(w_ffill)\n",
    ")\n",
    "\n",
    "# 5. Fill TMIN using backward fill (next valid day)\n",
    "df_silver_filled = df_silver_filled.withColumn(\n",
    "    \"TMIN_bfill\",\n",
    "    last(\"TMIN\", ignorenulls=True).over(w_bfill)\n",
    ")\n",
    "\n",
    "# 6. Combine original TMIN → forward fill → backward fill\n",
    "df_silver_filled = df_silver_filled.withColumn(\n",
    "    \"TMIN\",\n",
    "    coalesce(col(\"TMIN\"), col(\"TMIN_ffill\"), col(\"TMIN_bfill\"))\n",
    ")\n",
    "\n",
    "\n",
    "# 7. Fill TAVG if missing, using (TMAX + TMIN) / 2\n",
    "df_silver_filled = df_silver_filled.withColumn(\n",
    "    \"TAVG\",\n",
    "    when(col(\"TAVG\").isNull(), (col(\"TMAX\") + col(\"TMIN\")) / 2)\n",
    "    .otherwise(col(\"TAVG\"))\n",
    ")\n",
    "\n",
    "\n",
    "# 8. Remove temporary fill columns\n",
    "df_silver_filled = df_silver_filled.drop(\n",
    "    \"TMAX_ffill\", \"TMAX_bfill\",\n",
    "    \"TMIN_ffill\", \"TMIN_bfill\"\n",
    ")\n",
    "\n",
    "# 9. Show final cleaned Silver table\n",
    "df_silver_filled = df_silver_filled.orderBy(\"ID\", \"date\")\n",
    "display(df_silver_filled.limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8003f8dc-8d36-4963-a76e-7893872746b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Save Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8aef8c67-f931-4e2d-b677-3c0bd88102e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_path = \"abfss://lakehouse@qatarclimateanalysis.dfs.core.windows.net/silver/gcc_silver.parquet\"\n",
    "df_silver_filled.write.mode(\"overwrite\").parquet(silver_path)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Bronze_to_Silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
